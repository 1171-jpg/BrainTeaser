{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import RobertaTokenizer, RobertaForMultipleChoice, AdamW, get_linear_schedule_with_warmup\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.metrics import accuracy_score\n",
    "import json\n",
    "import json_lines\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultipleChoiceDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_ids, attention_mask, label = self.data[idx]\n",
    "        return {\n",
    "            'input_ids': input_ids,\n",
    "            'attention_mask': attention_mask,\n",
    "            'labels': label\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_map = {'A':0,'B':1,'C':2,'D':3,'E':4}\n",
    "def load_data(file_path):\n",
    "    data = []\n",
    "    with open(file_path, 'rb') as f: \n",
    "        for item in json_lines.reader(f):\n",
    "            data.append(item)\n",
    "\n",
    "    processed_data = []\n",
    "    for item in data:\n",
    "        question = item['question']['stem']\n",
    "        options = [_['text'] for _ in item['question']['choices']]\n",
    "        examples = []\n",
    "        for option in options:\n",
    "            text = question + \" \" + option\n",
    "            encoded = tokenizer.encode_plus(\n",
    "                text,\n",
    "                truncation=True,\n",
    "                max_length=512,\n",
    "                padding='max_length',\n",
    "                return_attention_mask=True,\n",
    "                return_tensors='pt'\n",
    "            )\n",
    "            examples.append(encoded)\n",
    "\n",
    "        input_ids = torch.stack([example['input_ids'] for example in examples]).squeeze()\n",
    "        attention_mask = torch.stack([example['attention_mask'] for example in examples]).squeeze()\n",
    "\n",
    "        label = torch.tensor(answer_map[item['answerKey']])\n",
    "\n",
    "        processed_data.append((input_ids, attention_mask, label))\n",
    "\n",
    "    return processed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RobertaForMultipleChoice.from_pretrained('roberta-large')\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = load_data(\"../data/rs_train.jsonl\")\n",
    "valid_data = load_data(\"../data/rs_dev.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MultipleChoiceDataset(train_data)\n",
    "valid_dataset = MultipleChoiceDataset(valid_data)\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "train_loader = DataLoader(train_dataset, shuffle=True, batch_size=batch_size)\n",
    "valid_loader = DataLoader(valid_dataset, shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "optimizer = AdamW(model.parameters(), lr=1e-5)\n",
    "epochs = 3\n",
    "total_steps = len(train_loader) * epochs\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    model.save_pretrained('model_{}_directory'.format(epoch))\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    average_loss = 0\n",
    "    for index, batch in tqdm(enumerate(train_loader)):\n",
    "        inputs = {key: val.to(device) for key, val in batch.items() if key != \"labels\"}\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "        outputs = model(**inputs, labels=labels)\n",
    "        if index ==0:\n",
    "            print(outputs)\n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.item()\n",
    "        average_loss += loss.item()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        if index%100==0:\n",
    "            print(\"###{}####: Average loss: {}\".format(index,average_loss / 100))\n",
    "            average_loss = 0\n",
    "\n",
    "    avg_train_loss = total_loss / len(train_loader)\n",
    "\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    true_labels = []\n",
    "    for batch in tqdm(valid_loader):\n",
    "        inputs = {key: val.to(device) for key, val in batch.items() if key != \"labels\"}\n",
    "        labels = batch[\"labels\"]\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        preds.extend(torch.argmax(logits, dim=1).detach().cpu().numpy())\n",
    "        true_labels.extend(labels.numpy())\n",
    "\n",
    "    acc = accuracy_score(true_labels, preds)\n",
    "    print(f'Epoch: {epoch+1}, Train loss: {avg_train_loss}, Validation accuracy: {acc}')\n",
    "    model.save_pretrained('model_{}_directory'.format(epoch))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
