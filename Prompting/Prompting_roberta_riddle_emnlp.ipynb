{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import RobertaTokenizer, RobertaForMultipleChoice, AdamW, get_linear_schedule_with_warmup\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.metrics import accuracy_score\n",
    "import json\n",
    "import json_lines\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_data_path = \"\"\n",
    "wordplay_data_list = \"\"\n",
    "sentence_data_list = list(np.load(sentence_data_path,allow_pickle=True))\n",
    "wordplay_data_list = list(np.load(wordplay_data_list,allow_pickle=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_list = sentence_data_list + wordplay_data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = ''\n",
    "model = RobertaForMultipleChoice.from_pretrained(model_path)\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultipleChoiceDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_ids, attention_mask, label = self.data[idx]\n",
    "        return {\n",
    "            'input_ids': input_ids,\n",
    "            'attention_mask': attention_mask,\n",
    "            'labels': label\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_map = {'A':0,'B':1,'C':2,'D':3}\n",
    "def load_data(test_data_list):\n",
    "\n",
    "    processed_data = []\n",
    "    for item in test_data_list:\n",
    "        question = item['question']\n",
    "        options = [_ for _ in item['choice_list']]\n",
    "\n",
    "        examples = []\n",
    "        for option in options:\n",
    "            text = question + \" \" + option\n",
    "            encoded = tokenizer.encode_plus(\n",
    "                text,\n",
    "                truncation=True,\n",
    "                max_length=512,\n",
    "                padding='max_length',\n",
    "                return_attention_mask=True,\n",
    "                return_tensors='pt'\n",
    "            )\n",
    "            examples.append(encoded)\n",
    "\n",
    "        input_ids = torch.stack([example['input_ids'] for example in examples]).squeeze()\n",
    "        attention_mask = torch.stack([example['attention_mask'] for example in examples]).squeeze()\n",
    "\n",
    "        label = torch.tensor(item['label'])\n",
    "\n",
    "        processed_data.append((input_ids, attention_mask, label))\n",
    "\n",
    "    return processed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_data = load_data(test_data_list)\n",
    "valid_dataset = MultipleChoiceDataset(valid_data)\n",
    "batch_size=4\n",
    "valid_loader = DataLoader(valid_dataset, shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "preds = []\n",
    "for batch in tqdm(valid_loader):\n",
    "    inputs = {key: val.to(device) for key, val in batch.items() if key != \"labels\"}\n",
    "    labels = batch[\"labels\"]\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    logits = outputs.logits\n",
    "    preds.extend(torch.argmax(logits, dim=1).detach().cpu().numpy())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_map = ['A','B','C','D']\n",
    "for pred,item in zip(preds,test_data_list):\n",
    "    item['predict'] = pred_map[int[pred]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_play,sentence_play = getResultdata(test_data_list)\n",
    "final_result = getSeperateResult(word_play,sentence_play)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
